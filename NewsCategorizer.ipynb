{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96c5525c",
   "metadata": {},
   "source": [
    "##### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1958d39f",
   "metadata": {},
   "source": [
    "Create an automated system that accurately classifies news articles into relevant categories such as education, science, politics, etc., to aid in efficient content categorization and organization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "633be9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64822917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in c:\\users\\pooji\\anaconda3\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\pooji\\anaconda3\\lib\\site-packages (from lightgbm) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\pooji\\anaconda3\\lib\\site-packages (from lightgbm) (1.9.1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "!pip install lightgbm\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19ad5d",
   "metadata": {},
   "source": [
    "## Step 1: Read the data and clean it using regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f62c452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>headline</th>\n",
       "      <th>short_description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>These Lesbian Farmers Aren't Here To Take Over...</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>QUEER VOICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Taking the 'I' Out of Volunteering</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "      <td>IMPACT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How Losing The Love Of My Life Made Me Distrus...</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "      <td>QUEER VOICES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Sam Brownback Declares War On Kansas: This Is ...</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "      <td>POLITICS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Brexit And The Long History Of English Propert...</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "      <td>WORLD NEWS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                           headline  \\\n",
       "0           0  These Lesbian Farmers Aren't Here To Take Over...   \n",
       "1           1                 Taking the 'I' Out of Volunteering   \n",
       "2           2  How Losing The Love Of My Life Made Me Distrus...   \n",
       "3           3  Sam Brownback Declares War On Kansas: This Is ...   \n",
       "4           4  Brexit And The Long History Of English Propert...   \n",
       "\n",
       "                                   short_description      category  \n",
       "0  Rush Limbaugh seems to thinks queer farmers ar...  QUEER VOICES  \n",
       "1  Organizations that help nonprofits understand ...        IMPACT  \n",
       "2  \"If your introduction to the world is full of ...  QUEER VOICES  \n",
       "3  It’s not uncommon to see developments named af...      POLITICS  \n",
       "4  Thus in two centuries, the profile of the Brit...    WORLD NEWS  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('news_category.xlsx') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8194f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the null values\n",
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ce59b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0           False\n",
       "headline             False\n",
       "short_description    False\n",
       "category             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b031cc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate 'short_description' and 'headline' columns\n",
    "df['Text'] = df['short_description'].astype(str) + ' ' + df['headline'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe80215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['short_description', 'headline'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cffbce45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop(df.columns[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60b12cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUEER VOICES</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUEER VOICES</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WORLD NEWS</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       category                                               Text\n",
       "0  QUEER VOICES  Rush Limbaugh seems to thinks queer farmers ar...\n",
       "1        IMPACT  Organizations that help nonprofits understand ...\n",
       "2  QUEER VOICES  \"If your introduction to the world is full of ...\n",
       "3      POLITICS  It’s not uncommon to see developments named af...\n",
       "4    WORLD NEWS  Thus in two centuries, the profile of the Brit..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cafba01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          29578\n",
       "ENTERTAINMENT     11670\n",
       "HEALTHY LIVING     5265\n",
       "QUEER VOICES       4270\n",
       "THE WORLDPOST      3664\n",
       "PARENTS            3556\n",
       "SPORTS             3507\n",
       "BLACK VOICES       3452\n",
       "BUSINESS           3394\n",
       "COMEDY             3256\n",
       "WOMEN              3102\n",
       "MEDIA              2275\n",
       "WEIRD NEWS         2209\n",
       "IMPACT             2205\n",
       "WORLD NEWS         2175\n",
       "CRIME              2164\n",
       "GREEN              2046\n",
       "TASTE              1940\n",
       "RELIGION           1857\n",
       "TRAVEL             1678\n",
       "STYLE              1567\n",
       "ARTS & CULTURE     1339\n",
       "WORLDPOST          1242\n",
       "TECH               1231\n",
       "FIFTY              1042\n",
       "GOOD NEWS          1039\n",
       "LATINO VOICES      1021\n",
       "SCIENCE             978\n",
       "COLLEGE             921\n",
       "EDUCATION           892\n",
       "ARTS                863\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b12ff604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping the similar categories\n",
    "df['category'] = df['category'].replace({'SCIENCE': 'EDUCATION', 'ARTS & CULTURE': 'EDUCATION','ARTS': 'EDUCATION','COLLEGE': 'EDUCATION'})\n",
    "df['category'] = df['category'].replace({'MEDIA': 'GLOBAL','CRIME': 'GLOBAL','WEIRD NEWS': 'GLOBAL','WORLD NEWS': 'GLOBAL','GOOD NEWS': 'GLOBAL'})\n",
    "df['category'] = df['category'].replace({'SPORTS': 'ENTERTAINMENT','COMEDY': 'ENTERTAINMENT'})\n",
    "df['category'] = df['category'].replace({'TASTE': 'MISCELLANEOUS','PARENTS': 'MISCELLANEOUS','FIFTY': 'MISCELLANEOUS','STYLE': 'MISCELLANEOUS','GREEN': 'MISCELLANEOUS'})\n",
    "df['category'] = df['category'].replace({'BLACK VOICES': 'SOCIAL JUSTICE','QUEER VOICES': 'SOCIAL JUSTICE','LATINO VOICES': 'SOCIAL JUSTICE'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107bb239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POLITICS          29578\n",
       "ENTERTAINMENT     18433\n",
       "MISCELLANEOUS     10151\n",
       "GLOBAL             9862\n",
       "SOCIAL JUSTICE     8743\n",
       "HEALTHY LIVING     5265\n",
       "EDUCATION          4993\n",
       "THE WORLDPOST      3664\n",
       "BUSINESS           3394\n",
       "WOMEN              3102\n",
       "IMPACT             2205\n",
       "RELIGION           1857\n",
       "TRAVEL             1678\n",
       "WORLDPOST          1242\n",
       "TECH               1231\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fcdc904a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               Text  Category\n",
       "0  SOCIAL JUSTICE  Rush Limbaugh seems to thinks queer farmers ar...         9\n",
       "1          IMPACT  Organizations that help nonprofits understand ...         5\n",
       "2  SOCIAL JUSTICE  \"If your introduction to the world is full of ...         9\n",
       "3        POLITICS  It’s not uncommon to see developments named af...         7\n",
       "4          GLOBAL  Thus in two centuries, the profile of the Brit...         3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "# Fit the encoder on the categories and transform the variable\n",
    "df['Category'] = encoder.fit_transform(df['category'])\n",
    "\n",
    "# Print the DataFrame to see the encoded values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acfdae99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 105398 entries, 0 to 124988\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype \n",
      "---  ------    --------------   ----- \n",
      " 0   category  105398 non-null  object\n",
      " 1   Text      105398 non-null  object\n",
      " 2   Category  105398 non-null  int32 \n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 2.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aeff8ecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124984</th>\n",
       "      <td>THE WORLDPOST</td>\n",
       "      <td>The fallout from Turkey's attempted coup conti...</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124985</th>\n",
       "      <td>ENTERTAINMENT</td>\n",
       "      <td>Officials recommend he be deposed in the Unite...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124986</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It would \"diminish the guest experience of our...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124987</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>\"I have avoided doing that. I am trying to run...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124988</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>Colin Kaepernick's former team, the San Franci...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105398 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              category                                               Text  \\\n",
       "0       SOCIAL JUSTICE  Rush Limbaugh seems to thinks queer farmers ar...   \n",
       "1               IMPACT  Organizations that help nonprofits understand ...   \n",
       "2       SOCIAL JUSTICE  \"If your introduction to the world is full of ...   \n",
       "3             POLITICS  It’s not uncommon to see developments named af...   \n",
       "4               GLOBAL  Thus in two centuries, the profile of the Brit...   \n",
       "...                ...                                                ...   \n",
       "124984   THE WORLDPOST  The fallout from Turkey's attempted coup conti...   \n",
       "124985   ENTERTAINMENT  Officials recommend he be deposed in the Unite...   \n",
       "124986        POLITICS  It would \"diminish the guest experience of our...   \n",
       "124987        POLITICS  \"I have avoided doing that. I am trying to run...   \n",
       "124988        POLITICS  Colin Kaepernick's former team, the San Franci...   \n",
       "\n",
       "        Category  \n",
       "0              9  \n",
       "1              5  \n",
       "2              9  \n",
       "3              7  \n",
       "4              3  \n",
       "...          ...  \n",
       "124984        11  \n",
       "124985         2  \n",
       "124986         7  \n",
       "124987         7  \n",
       "124988         7  \n",
       "\n",
       "[105398 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c2b33aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>9</td>\n",
       "      <td>rush limbaugh seems to thinks queer farmers ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "      <td>5</td>\n",
       "      <td>organizations that help nonprofits understand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "      <td>9</td>\n",
       "      <td>\"if your introduction to the world is full of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "      <td>7</td>\n",
       "      <td>it’s not uncommon to see developments named af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "      <td>3</td>\n",
       "      <td>thus in two centuries, the profile of the brit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               Text  \\\n",
       "0  SOCIAL JUSTICE  Rush Limbaugh seems to thinks queer farmers ar...   \n",
       "1          IMPACT  Organizations that help nonprofits understand ...   \n",
       "2  SOCIAL JUSTICE  \"If your introduction to the world is full of ...   \n",
       "3        POLITICS  It’s not uncommon to see developments named af...   \n",
       "4          GLOBAL  Thus in two centuries, the profile of the Brit...   \n",
       "\n",
       "   Category                                               text  \n",
       "0         9  rush limbaugh seems to thinks queer farmers ar...  \n",
       "1         5  organizations that help nonprofits understand ...  \n",
       "2         9  \"if your introduction to the world is full of ...  \n",
       "3         7  it’s not uncommon to see developments named af...  \n",
       "4         3  thus in two centuries, the profile of the brit...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['Text'].apply(lambda x: str(x).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "603629c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "    cleaned_text = ' '.join(tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe320c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>Text</th>\n",
       "      <th>Category</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>Rush Limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>9</td>\n",
       "      <td>rush limbaugh seems to thinks queer farmers ar...</td>\n",
       "      <td>rush limbaugh seems thinks queer farmers threa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMPACT</td>\n",
       "      <td>Organizations that help nonprofits understand ...</td>\n",
       "      <td>5</td>\n",
       "      <td>organizations that help nonprofits understand ...</td>\n",
       "      <td>organizations help nonprofits understand use e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOCIAL JUSTICE</td>\n",
       "      <td>\"If your introduction to the world is full of ...</td>\n",
       "      <td>9</td>\n",
       "      <td>\"if your introduction to the world is full of ...</td>\n",
       "      <td>`` introduction world full men ’ want becomes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLITICS</td>\n",
       "      <td>It’s not uncommon to see developments named af...</td>\n",
       "      <td>7</td>\n",
       "      <td>it’s not uncommon to see developments named af...</td>\n",
       "      <td>’ uncommon see developments named displace som...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GLOBAL</td>\n",
       "      <td>Thus in two centuries, the profile of the Brit...</td>\n",
       "      <td>3</td>\n",
       "      <td>thus in two centuries, the profile of the brit...</td>\n",
       "      <td>thus two centuries , profile british france co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                               Text  \\\n",
       "0  SOCIAL JUSTICE  Rush Limbaugh seems to thinks queer farmers ar...   \n",
       "1          IMPACT  Organizations that help nonprofits understand ...   \n",
       "2  SOCIAL JUSTICE  \"If your introduction to the world is full of ...   \n",
       "3        POLITICS  It’s not uncommon to see developments named af...   \n",
       "4          GLOBAL  Thus in two centuries, the profile of the Brit...   \n",
       "\n",
       "   Category                                               text  \\\n",
       "0         9  rush limbaugh seems to thinks queer farmers ar...   \n",
       "1         5  organizations that help nonprofits understand ...   \n",
       "2         9  \"if your introduction to the world is full of ...   \n",
       "3         7  it’s not uncommon to see developments named af...   \n",
       "4         3  thus in two centuries, the profile of the brit...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  rush limbaugh seems thinks queer farmers threa...  \n",
       "1  organizations help nonprofits understand use e...  \n",
       "2  `` introduction world full men ’ want becomes ...  \n",
       "3  ’ uncommon see developments named displace som...  \n",
       "4  thus two centuries , profile british france co...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c7bec91f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         rush limbaugh seems thinks queer farmers threa...\n",
       "1         organizations help nonprofits understand use e...\n",
       "2         `` introduction world full men ’ want becomes ...\n",
       "3         ’ uncommon see developments named displace som...\n",
       "4         thus two centuries , profile british france co...\n",
       "                                ...                        \n",
       "124984    fallout turkey 's attempted coup continues cau...\n",
       "124985    officials recommend deposed united states . br...\n",
       "124986    would `` diminish guest experience brand , '' ...\n",
       "124987    `` avoided . trying run issue-oriented campaig...\n",
       "124988    colin kaepernick 's former team , san francisc...\n",
       "Name: clean_text, Length: 105398, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f7ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y and then Splitting the data\n",
    "X = df.clean_text\n",
    "y = df['Category']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fccbaf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((84318,), (21080,), (84318,), (21080,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a550df1",
   "metadata": {},
   "source": [
    "## Step 2. Apply Count Vectorizer and Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371de6c0",
   "metadata": {},
   "source": [
    "#### Using MultinomialNB with Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b13200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply count vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb277707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<84318x56438 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1379694 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "195bde17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<21080x56438 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 338126 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d08a916b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a model using Naive Bayes (MultinomialNB)\n",
    "model = MultinomialNB(alpha=0.1)\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "080a8021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6300284629981024\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "y_pred = model.predict(X_test_vec)\n",
    "accuracy_mNB_CV = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_mNB_CV)\n",
    "accuracy = {'Model':\"MultinomialNB with Count Vectorizer\",'Accuracy':accuracy_mNB_CV}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7d7f203b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB with Count Vectorizer</td>\n",
       "      <td>0.630028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Model  Accuracy\n",
       "0  MultinomialNB with Count Vectorizer  0.630028"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(columns=['Model','Accuracy'])\n",
    "result = result.append(accuracy,ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61209ae",
   "metadata": {},
   "source": [
    "#### Using LGBMClassifier with hyperparameter tunning by count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "830bf3a9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.997941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.008393 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.038723 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.995556 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.057254 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.081465 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.028632 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.314173 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.350675 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.118894 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.275219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.199635 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.996542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.010358 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.024242 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.003189 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.999589 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.008531 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.024037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.983666 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.023551 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.016076 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.992570 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.052092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.006589 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.686557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.751263 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.759855 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.718697 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.709555 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.757992 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.890533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.876819 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.055786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.876803 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.826012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.939299 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.956455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.908490 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.942501 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.937878 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.984691 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.909308 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.946428 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.006289 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.001121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.941255 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.933714 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.976157 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.918097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.988205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.995283 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.972588 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.981262 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.950729 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.997979 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.976975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.959832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.935455 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.974278 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.930036 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.890982 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.881561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.934243 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.923084 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.981765 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.917031 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.883699 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.985545 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.960238 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.962591 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.907787 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.008565 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.925065 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.947487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.949095 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.923327 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.951700 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.986983 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.947483 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.914276 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.933072 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.935530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.925046 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.972669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.934010 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.907783 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.964608 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.918109 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.942380 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.938305 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.984912 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.039919 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.954728 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.967434 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.969440 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.933264 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.943530 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.938032 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.980475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.041876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.050514 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.927659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.036574 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.087259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.958329 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.029000 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.953572 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.987321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.982482 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.945593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.003967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.959791 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.965123 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.904399 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.977942 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.992908 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.943916 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.978874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.036933 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.954645 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.968640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.945484 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.896491 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.041012 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.922770 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 2.037953 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.974804 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.130057 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.970392 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23337\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7675\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.011180\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.425877\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.004016 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23232\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7627\n",
      "[LightGBM] [Info] Start training from score -3.430746\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744279\n",
      "[LightGBM] [Info] Start training from score -2.368835\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865023\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269431\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494769\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.012164 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23310\n",
      "[LightGBM] [Info] Number of data points in the train set: 67454, number of used features: 7654\n",
      "[LightGBM] [Info] Start training from score -3.431204\n",
      "[LightGBM] [Info] Start training from score -3.049546\n",
      "[LightGBM] [Info] Start training from score -1.744194\n",
      "[LightGBM] [Info] Start training from score -2.368676\n",
      "[LightGBM] [Info] Start training from score -3.010879\n",
      "[LightGBM] [Info] Start training from score -3.865731\n",
      "[LightGBM] [Info] Start training from score -2.329084\n",
      "[LightGBM] [Info] Start training from score -1.269378\n",
      "[LightGBM] [Info] Start training from score -4.050178\n",
      "[LightGBM] [Info] Start training from score -2.494949\n",
      "[LightGBM] [Info] Start training from score -4.444640\n",
      "[LightGBM] [Info] Start training from score -3.365149\n",
      "[LightGBM] [Info] Start training from score -4.133559\n",
      "[LightGBM] [Info] Start training from score -3.536972\n",
      "[LightGBM] [Info] Start training from score -4.427117\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.112566 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23331\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7646\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.010894\n",
      "[LightGBM] [Info] Start training from score -3.865746\n",
      "[LightGBM] [Info] Start training from score -2.329099\n",
      "[LightGBM] [Info] Start training from score -1.269393\n",
      "[LightGBM] [Info] Start training from score -4.050193\n",
      "[LightGBM] [Info] Start training from score -2.494964\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.364734\n",
      "[LightGBM] [Info] Start training from score -4.133574\n",
      "[LightGBM] [Info] Start training from score -3.536987\n",
      "[LightGBM] [Info] Start training from score -4.427132\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.938210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 23326\n",
      "[LightGBM] [Info] Number of data points in the train set: 67455, number of used features: 7659\n",
      "[LightGBM] [Info] Start training from score -3.431219\n",
      "[LightGBM] [Info] Start training from score -3.049561\n",
      "[LightGBM] [Info] Start training from score -1.744209\n",
      "[LightGBM] [Info] Start training from score -2.368691\n",
      "[LightGBM] [Info] Start training from score -3.011195\n",
      "[LightGBM] [Info] Start training from score -3.865038\n",
      "[LightGBM] [Info] Start training from score -2.329251\n",
      "[LightGBM] [Info] Start training from score -1.269446\n",
      "[LightGBM] [Info] Start training from score -4.049342\n",
      "[LightGBM] [Info] Start training from score -2.494784\n",
      "[LightGBM] [Info] Start training from score -4.444655\n",
      "[LightGBM] [Info] Start training from score -3.365163\n",
      "[LightGBM] [Info] Start training from score -4.134500\n",
      "[LightGBM] [Info] Start training from score -3.536477\n",
      "[LightGBM] [Info] Start training from score -4.425892\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.485321 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 26964\n",
      "[LightGBM] [Info] Number of data points in the train set: 84318, number of used features: 8816\n",
      "[LightGBM] [Info] Start training from score -3.431027\n",
      "[LightGBM] [Info] Start training from score -3.049552\n",
      "[LightGBM] [Info] Start training from score -1.744234\n",
      "[LightGBM] [Info] Start training from score -2.368746\n",
      "[LightGBM] [Info] Start training from score -3.011005\n",
      "[LightGBM] [Info] Start training from score -3.865312\n",
      "[LightGBM] [Info] Start training from score -2.329121\n",
      "[LightGBM] [Info] Start training from score -1.269416\n",
      "[LightGBM] [Info] Start training from score -4.050013\n",
      "[LightGBM] [Info] Start training from score -2.494847\n",
      "[LightGBM] [Info] Start training from score -4.444646\n",
      "[LightGBM] [Info] Start training from score -3.365069\n",
      "[LightGBM] [Info] Start training from score -4.133750\n",
      "[LightGBM] [Info] Start training from score -3.536876\n",
      "[LightGBM] [Info] Start training from score -4.426627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "\n",
    "X_train_vec = X_train_vec.astype(np.float32)\n",
    "y_train = y_train.astype(np.float32)\n",
    "\n",
    "# Create a LightGBM classifier object\n",
    "lgb_classifier = lgb.LGBMClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'num_leaves': [10, 20, 30],\n",
    "    'learning_rate': [0.1, 0.01, 0.001],\n",
    "    'n_estimators': [100, 300, 500],\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=lgb_classifier, param_grid=param_grid)\n",
    "\n",
    "# Perform the grid search\n",
    "grid_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Get the best hyperparameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61dbf3b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.1, 'n_estimators': 500, 'num_leaves': 20}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0bf8eb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<84318x56438 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 1379694 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the feature data type to np.float32\n",
    "X_train_vec = X_train_vec.astype(np.float32)\n",
    "X_train_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c8dead9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.539721 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 26964\n",
      "[LightGBM] [Info] Number of data points in the train set: 84318, number of used features: 8816\n",
      "[LightGBM] [Info] Start training from score -3.431027\n",
      "[LightGBM] [Info] Start training from score -3.049552\n",
      "[LightGBM] [Info] Start training from score -1.744234\n",
      "[LightGBM] [Info] Start training from score -2.368746\n",
      "[LightGBM] [Info] Start training from score -3.011005\n",
      "[LightGBM] [Info] Start training from score -3.865312\n",
      "[LightGBM] [Info] Start training from score -2.329121\n",
      "[LightGBM] [Info] Start training from score -1.269416\n",
      "[LightGBM] [Info] Start training from score -4.050013\n",
      "[LightGBM] [Info] Start training from score -2.494847\n",
      "[LightGBM] [Info] Start training from score -4.444646\n",
      "[LightGBM] [Info] Start training from score -3.365069\n",
      "[LightGBM] [Info] Start training from score -4.133750\n",
      "[LightGBM] [Info] Start training from score -3.536876\n",
      "[LightGBM] [Info] Start training from score -4.426627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(n_estimators=500, num_leaves=20, random_state=42)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a LightGBM classifier object\n",
    "lgb_classifier = lgb.LGBMClassifier(num_leaves =20,learning_rate= 0.1,n_estimators= 500,random_state=42)\n",
    "lgb_classifier.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51cad480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test feature data type to np.float32\n",
    "X_test_vec = X_test_vec.astype(np.float32)\n",
    "# Predict the labels for the test set\n",
    "y_pred = lgb_classifier.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "303c2464",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6416034155597723\n",
      "{'Model': 'Using LGBMClassifier with hyperparameter tunning by count vectorizer', 'Accuracy': 0.6416034155597723}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the classifier\n",
    "accuracy_LGBM_CV = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_LGBM_CV)\n",
    "accuracy = {'Model':\"Using LGBMClassifier with hyperparameter tunning by count vectorizer\",'Accuracy':accuracy_LGBM_CV}\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a2eebde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MultinomialNB with Count Vectorizer</td>\n",
       "      <td>0.630028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Using LGBMClassifier with hyperparameter tunni...</td>\n",
       "      <td>0.641603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Model  Accuracy\n",
       "0                MultinomialNB with Count Vectorizer  0.630028\n",
       "1  Using LGBMClassifier with hyperparameter tunni...  0.641603"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = result.append(accuracy,ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6fce97",
   "metadata": {},
   "source": [
    "## Step 3: Apply Tf-Idf transformation and build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e191cfe",
   "metadata": {},
   "source": [
    "#### Using MultinomialNB with Tf-Idf transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e303412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Tf-Idf transformation\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68e9de2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a model using Naive Bayes (MultinomialNB)\n",
    "model_tfidf = MultinomialNB()\n",
    "model_tfidf.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0cfbc530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1.0, 2.0]\n",
    "}\n",
    "\n",
    "# Build a model using Naive Bayes (MultinomialNB)\n",
    "model_tfidf = MultinomialNB()\n",
    "# Tune the model using GridSearchCV\n",
    "grid_search_tfidf = GridSearchCV(model_tfidf, param_grid, cv=5)\n",
    "grid_search_tfidf.fit(X_train_tfidf, y_train)\n",
    "best_model_tfidf = grid_search_tfidf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8a7b112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d467b8b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6053605313092979\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "y_pred_tfidf = best_model_tfidf.predict(X_test_tfidf)\n",
    "accuracy_tfidf = accuracy_score(y_test, y_pred_tfidf)\n",
    "confusion_mat_tfidf = confusion_matrix(y_test, y_pred_tfidf)\n",
    "print(\"Accuracy:\", accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfae16b6",
   "metadata": {},
   "source": [
    "#### Using Random ForestClassifier with hyperparameter tunning by Tf-Idf transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aca504f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(n_estimators=300)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=GradientBoostingClassifier(learning_rate= 0.1, max_depth=3, n_estimators=300)\n",
    "model.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "10132176",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5958728652751423"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_vec)\n",
    "ac = accuracy_score(y_test, y_pred)\n",
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa9d3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [5, 10, 20],  # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    # Number of features to consider when looking for the best split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347162f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Random Forest classifier with best parameter\n",
    "GB = GradientBoostingClassifier()\n",
    "\n",
    "# Perform randomized search\n",
    "random_search = RandomizedSearchCV(estimator=GB, param_distributions=param_grid, n_iter=10)\n",
    "random_search.fit(X_train_vec, y_train)\n",
    "\n",
    "# Get the best parameters found by randomized search\n",
    "best_params_random = random_search.best_params_\n",
    "print(\"Best Parameters (Randomized Search):\", best_params_random)\n",
    "\n",
    "# Evaluate the model with the best parameters on the test set\n",
    "best_gb = GradientBoostingClassifier(**best_params_random)\n",
    "best_gb.fit(X_train_ec, y_train)\n",
    "accuracy = best_gb.score(X_test_vec, y_test)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf32f67",
   "metadata": {},
   "source": [
    "#### Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nModel Performance Comparison:\")\n",
    "print(\"Count Vectorizer Model Accuracy:\", accuracy)\n",
    "print(\"Tf-Idf Model Accuracy:\", accuracy_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2fc0c9b",
   "metadata": {},
   "source": [
    "## Getting Best accuracy in LGBMClassifier with count vectorizer which is 0.641"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
